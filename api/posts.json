{
  "posts": [
    {
      "slug": "vlm-series-roadmap",
      "title": "VLM Roadmap: Từ nền tảng đến triển khai thực tế",
      "date": "2025-03-21",
      "category": "Vision-Language Models",
      "tags": ["VLM", "Multimodal", "Roadmap"],
      "excerpt": "Bức tranh toàn cảnh về series Vision-Language Models: cấu trúc 4 tầng, liên kết tới từng bài chi tiết, mục tiêu học tập và cách khai thác tài nguyên mã nguồn.",
      "author": "ThanhLamDev",
      "readingTime": 12,
      "featured": true,
      "publishedAt": "2025-03-21T08:00:00Z",
      "updatedAt": "2025-03-21T08:00:00Z",
      "image": "/assets/images/vlm-roadmap.jpg",
      "description": "Overview of the Vision-Language Models series"
    },
    {
      "slug": "vlm-history-early-era",
      "title": "Từ Show-and-Tell đến ViLBERT: Khởi nguyên Vision-Language Models",
      "date": "2025-03-21",
      "category": "Vision-Language Models",
      "tags": ["History", "Captioning", "ViLBERT"],
      "excerpt": "Ôn lại các mốc quan trọng giai đoạn 2015–2019: image captioning, attention, co-attention transformers – nền móng cho VLM hiện đại.",
      "author": "ThanhLamDev",
      "readingTime": 17,
      "featured": false,
      "publishedAt": "2025-03-21T09:00:00Z",
      "updatedAt": "2025-03-21T09:00:00Z",
      "image": "/assets/images/vlm-history.jpg",
      "description": "Historical foundations of vision-language models"
    },
    {
      "slug": "vlm-multimodal-fundamentals",
      "title": "Multimodal Fundamentals: Nền tảng lý thuyết cho Vision-Language Models",
      "date": "2025-03-22",
      "category": "Vision-Language Models",
      "tags": ["Multimodal", "Theory", "Representation"],
      "excerpt": "Phân tích khung toán học của học đa phương thức, từ biểu diễn liên kết đến cơ chế chú ý chéo – bước đệm cho các kiến trúc VLM hiện đại.",
      "author": "ThanhLamDev",
      "readingTime": 18,
      "featured": false,
      "publishedAt": "2025-03-22T08:00:00Z",
      "updatedAt": "2025-03-22T08:00:00Z",
      "image": "/assets/images/vlm-fundamentals.jpg",
      "description": "Theoretical recap for multimodal learning"
    },
    {
      "slug": "vlm-vision-encoders-tokenization",
      "title": "Vision Encoders & Tokenization cho VLM: ViT, CNN và các thủ thuật patch",
      "date": "2025-03-23",
      "category": "Vision-Language Models",
      "tags": ["Vision Encoder", "Tokenization", "ViT"],
      "excerpt": "So sánh các kiến trúc vision encoder, chiến lược tokenization và dự án mã nguồn giúp đưa hình ảnh vào không gian ngôn ngữ.",
      "author": "ThanhLamDev",
      "readingTime": 20,
      "featured": false,
      "publishedAt": "2025-03-23T08:00:00Z",
      "updatedAt": "2025-03-23T08:00:00Z",
      "image": "/assets/images/vlm-vision-token.jpg",
      "description": "Comparing vision encoders and patch strategies"
    },
    {
      "slug": "vlm-text-encoders-grounding",
      "title": "Text Encoders & Language Grounding trong VLM",
      "date": "2025-03-24",
      "category": "Vision-Language Models",
      "tags": ["Text Encoder", "Grounding", "BERT"],
      "excerpt": "Bóc tách vai trò encoder ngôn ngữ, cách kết nối với vision features và các chiến lược grounding câu hỏi-hình ảnh.",
      "author": "ThanhLamDev",
      "readingTime": 18,
      "featured": false,
      "publishedAt": "2025-03-24T08:00:00Z",
      "updatedAt": "2025-03-24T08:00:00Z",
      "image": "/assets/images/vlm-text-encoder.jpg",
      "description": "Language tower choices and grounding techniques"
    },
    {
      "slug": "vlm-pretraining-objectives",
      "title": "Pretraining Objectives cho VLM: Contrastive, Generative và Hybrid",
      "date": "2025-03-25",
      "category": "Vision-Language Models",
      "tags": ["Pretraining", "Contrastive", "Captioning"],
      "excerpt": "Phân loại các mục tiêu huấn luyện đa phương thức và so sánh ưu/nhược điểm của từng nhóm với minh họa toán học.",
      "author": "ThanhLamDev",
      "readingTime": 17,
      "featured": false,
      "publishedAt": "2025-03-25T08:00:00Z",
      "updatedAt": "2025-03-25T08:00:00Z",
      "image": "/assets/images/vlm-objectives.jpg",
      "description": "Taxonomy of VLM pretraining losses"
    },
    {
      "slug": "vlm-clip-architecture",
      "title": "CLIP Deep Dive: Kiến trúc, huấn luyện và bài học thực tế",
      "date": "2025-03-26",
      "category": "Vision-Language Models",
      "tags": ["CLIP", "Contrastive", "OpenCLIP"],
      "excerpt": "Giải phẫu CLIP: kiến trúc đôi tower, loss InfoNCE, tricks huấn luyện và cách fine-tune CLIP làm nền cho dự án VLM.",
      "author": "ThanhLamDev",
      "readingTime": 20,
      "featured": false,
      "publishedAt": "2025-03-26T08:00:00Z",
      "updatedAt": "2025-03-26T08:00:00Z",
      "image": "/assets/images/vlm-clip.jpg",
      "description": "Detailed analysis of CLIP architecture and training"
    },
    {
      "slug": "vlm-blip-series",
      "title": "BLIP & BLIP-2: Cầu nối encoder hình ảnh và LLM",
      "date": "2025-03-27",
      "category": "Vision-Language Models",
      "tags": ["BLIP", "BLIP-2", "Q-Former"],
      "excerpt": "Giải thích cách BLIP và BLIP-2 tách rời vision encoder, text encoder và LLM; phân tích Q-Former, captioning, VQA và các trick fine-tuning.",
      "author": "ThanhLamDev",
      "readingTime": 21,
      "featured": false,
      "publishedAt": "2025-03-27T08:00:00Z",
      "updatedAt": "2025-03-27T08:00:00Z",
      "image": "/assets/images/vlm-blip.jpg",
      "description": "Understanding BLIP and BLIP-2 pipelines"
    },
    {
      "slug": "vlm-token-compression",
      "title": "Token Compression & Efficiency trong VLM",
      "date": "2025-03-30",
      "category": "Vision-Language Models",
      "tags": ["Token Compression", "Perceiver", "ToMe"],
      "excerpt": "Tối ưu số lượng token hình ảnh: Perceiver Resampler, Q-Former, Token Merging, EVA patch pruning và benchmark hiệu năng.",
      "author": "ThanhLamDev",
      "readingTime": 19,
      "featured": false,
      "publishedAt": "2025-03-30T08:00:00Z",
      "updatedAt": "2025-03-30T08:00:00Z",
      "image": "/assets/images/vlm-token-compression.jpg",
      "description": "Efficiency techniques for visual tokens"
    },
    {
      "slug": "vlm-llava-training",
      "title": "Huấn luyện LLaVA: Từ data chuẩn hóa đến inference chat đa hình",
      "date": "2025-03-28",
      "category": "Vision-Language Models",
      "tags": ["LLaVA", "Instruction Tuning", "LoRA"],
      "excerpt": "Walkthrough chi tiết pipeline LLaVA: chuẩn hoá dữ liệu, projection layer, LoRA finetuning và deploy inference server.",
      "author": "ThanhLamDev",
      "readingTime": 22,
      "featured": false,
      "publishedAt": "2025-03-28T08:00:00Z",
      "updatedAt": "2025-03-28T08:00:00Z",
      "image": "/assets/images/vlm-llava.jpg",
      "description": "Step-by-step training pipeline for LLaVA"
    },
    {
      "slug": "vlm-instruction-tuning",
      "title": "Instruction Tuning & Alignment cho VLM",
      "date": "2025-03-29",
      "category": "Vision-Language Models",
      "tags": ["Instruction Tuning", "RLHF", "Alignment"],
      "excerpt": "Chiến thuật align VLM với yêu cầu người dùng: dữ liệu đối thoại, SFT, RLHF, evaluator và safety filter.",
      "author": "ThanhLamDev",
      "readingTime": 21,
      "featured": false,
      "publishedAt": "2025-03-29T08:00:00Z",
      "updatedAt": "2025-03-29T08:00:00Z",
      "image": "/assets/images/vlm-instruction.jpg",
      "description": "Alignment techniques for multimodal assistants"
    },
    {
      "slug": "vlm-finetuning-lora",
      "title": "Fine-tuning VLM với LoRA & Adapter Toolkit",
      "date": "2025-03-31",
      "category": "Vision-Language Models",
      "tags": ["LoRA", "Fine-tuning", "Adapter"],
      "excerpt": "Hướng dẫn xây dựng toolkit fine-tuning VLM với LoRA, IA3, AdapterFusion; so sánh chi phí và chất lượng trên CLIP, BLIP-2, LLaVA.",
      "author": "ThanhLamDev",
      "readingTime": 20,
      "featured": false,
      "publishedAt": "2025-03-31T08:00:00Z",
      "updatedAt": "2025-03-31T08:00:00Z",
      "image": "/assets/images/vlm-lora.jpg",
      "description": "PEFT strategies for VLM fine-tuning"
    },
    {
      "slug": "vlm-evaluation-benchmarks",
      "title": "Đánh giá VLM: Benchmark, Metrics và quy trình phân tích lỗi",
      "date": "2025-04-01",
      "category": "Vision-Language Models",
      "tags": ["Evaluation", "Benchmark", "Metrics"],
      "excerpt": "Danh mục benchmark quan trọng cho VLM, hướng dẫn tính metrics và pipeline phân tích lỗi/hallucination.",
      "author": "ThanhLamDev",
      "readingTime": 19,
      "featured": false,
      "publishedAt": "2025-04-01T08:00:00Z",
      "updatedAt": "2025-04-01T08:00:00Z",
      "image": "/assets/images/vlm-eval.jpg",
      "description": "Evaluation pipelines for VLM systems"
    },
    {
      "slug": "vlm-multimodal-rag-ocr",
      "title": "Ứng dụng VLM: Multimodal Retrieval, OCR & RAG",
      "date": "2025-04-02",
      "category": "Vision-Language Models",
      "tags": ["Retrieval", "OCR", "RAG"],
      "excerpt": "Hướng dẫn xây dựng hệ thống RAG đa phương thức, xử lý OCR với VLM và tối ưu pipeline tìm kiếm hình ảnh.",
      "author": "ThanhLamDev",
      "readingTime": 20,
      "featured": false,
      "publishedAt": "2025-04-02T08:00:00Z",
      "updatedAt": "2025-04-02T08:00:00Z",
      "image": "/assets/images/vlm-application.jpg",
      "description": "Applying VLMs to retrieval and OCR"
    },
    {
      "slug": "vlm-sota-2025-trends",
      "title": "VLM SOTA 2025: Gemini, GPT-4V, InternVL2 và những hướng nghiên cứu mới",
      "date": "2025-04-03",
      "category": "Vision-Language Models",
      "tags": ["SOTA", "Gemini", "GPT-4V", "InternVL"],
      "excerpt": "Tổng hợp các mô hình VLM mạnh nhất 2024–2025, phân tích kỹ thuật nổi bật và dự báo xu hướng nghiên cứu.",
      "author": "ThanhLamDev",
      "readingTime": 23,
      "featured": true,
      "publishedAt": "2025-04-03T08:00:00Z",
      "updatedAt": "2025-04-03T08:00:00Z",
      "image": "/assets/images/vlm-sota.jpg",
      "description": "Latest trends in vision-language research"
    },
    {
      "slug": "flow-matching-theory",
      "title": "Flow Matching: Từ lý thuyết đến thực hành với PyTorch",
      "date": "2025-10-13",
      "category": "Flow Matching",
      "tags": ["Flow Matching", "PyTorch", "Generative AI", "Theory"],
      "excerpt": "Deep dive vào Flow Matching theory, so sánh với Score-based Diffusion Models, và complete implementation từ scratch. Phân tích Rectified Flow và các sampling techniques hiện đại.",
      "author": "ThanhLamDev",
      "readingTime": 15,
      "featured": true,
      "publishedAt": "2025-10-13T10:00:00Z",
      "updatedAt": "2025-10-13T10:00:00Z",
      "image": "/assets/images/flow-matching.jpg",
      "description": "Comprehensive guide to Flow Matching for generative modeling"
    },
    {
      "slug": "ddpm-explained",
      "title": "DDPM Explained: Toán học đằng sau Diffusion Models",
      "date": "2025-10-12",
      "category": "DDPM",
      "tags": ["DDPM", "Diffusion", "Mathematics", "Deep Learning"],
      "excerpt": "Phân tích chi tiết forward process, reverse process, training objective và sampling algorithms. So sánh DDPM vs DDIM vs DPM-Solver với practical benchmarks.",
      "author": "ThanhLamDev",
      "readingTime": 12,
      "featured": false,
      "publishedAt": "2025-10-12T14:00:00Z",
      "updatedAt": "2025-10-12T14:00:00Z",
      "image": "/assets/images/ddpm.jpg",
      "description": "Mathematical foundations of Denoising Diffusion Probabilistic Models"
    },
    {
      "slug": "generative-ai-overview",
      "title": "Generative AI Landscape 2025: GANs, VAEs, và Diffusion Models",
      "date": "2025-10-10",
      "category": "Generative AI",
      "tags": ["GANs", "VAEs", "Diffusion", "Generative AI", "Survey"],
      "excerpt": "Tổng quan toàn diện về các approaches trong Generative AI. So sánh performance, use cases và future directions của từng method với real-world examples.",
      "author": "ThanhLamDev",
      "readingTime": 20,
      "featured": false,
      "publishedAt": "2025-10-10T16:00:00Z",
      "updatedAt": "2025-10-10T16:00:00Z",
      "image": "/assets/images/generative-ai.jpg",
      "description": "Comprehensive survey of generative AI methods and applications"
    },
    {
      "slug": "pytorch-flow-matching-tutorial",
      "title": "Implementing Flow Matching từ đầu với PyTorch",
      "date": "2025-10-09",
      "category": "Tutorial",
      "tags": ["PyTorch", "Flow Matching", "Implementation", "Tutorial"],
      "excerpt": "Hướng dẫn code chi tiết để hiểu rõ cơ chế hoạt động của Flow Matching. Từ basic concepts đến advanced optimization techniques với practical examples.",
      "author": "ThanhLamDev",
      "readingTime": 25,
      "featured": true,
      "publishedAt": "2025-10-09T11:00:00Z",
      "updatedAt": "2025-10-09T11:00:00Z",
      "image": "/assets/images/pytorch-tutorial.jpg",
      "description": "Step-by-step PyTorch implementation of Flow Matching"
    },
    {
      "slug": "transformer-attention-mechanisms",
      "title": "Attention Mechanisms trong Transformers: Self, Cross, và Multi-Head",
      "date": "2025-10-08",
      "category": "Transformers",
      "tags": ["Transformers", "Attention", "NLP", "Architecture"],
      "excerpt": "Deep dive vào attention mechanisms - core component của Transformers. Phân tích mathematical foundations và practical implementations cho NLP và Computer Vision.",
      "author": "ThanhLamDev",
      "readingTime": 16,
      "featured": false,
      "publishedAt": "2025-10-08T13:00:00Z",
      "updatedAt": "2025-10-08T13:00:00Z",
      "image": "/assets/images/attention.jpg",
      "description": "Understanding attention mechanisms in transformer architectures"
    }
  ],
  "categories": [
    {
      "name": "Vision-Language Models",
      "slug": "vision-language-models",
      "description": "Kiến trúc, huấn luyện và ứng dụng của Vision-Language Models",
      "color": "#0EA5E9",
      "postCount": 14
    },
    {
      "name": "Flow Matching",
      "slug": "flow-matching",
      "description": "Advanced generative modeling với continuous normalizing flows",
      "color": "#3B82F6",
      "postCount": 2
    },
    {
      "name": "DDPM",
      "slug": "ddpm",
      "description": "Denoising Diffusion Probabilistic Models và applications",
      "color": "#EF4444",
      "postCount": 1
    },
    {
      "name": "Generative AI",
      "slug": "generative-ai",
      "description": "Tổng quan về các phương pháp sinh dữ liệu",
      "color": "#8B5CF6",
      "postCount": 1
    },
    {
      "name": "Tutorial",
      "slug": "tutorial",
      "description": "Hands-on tutorials và implementations",
      "color": "#F59E0B",
      "postCount": 1
    },
    {
      "name": "Transformers",
      "slug": "transformers",
      "description": "Transformer architectures và applications",
      "color": "#EC4899",
      "postCount": 1
    }
  ],
  "tags": [
    "Flow Matching", "PyTorch", "Generative AI", "DDPM", "Diffusion",
    "VLM", "Multimodal", "History", "Captioning", "Vision Encoder", "Tokenization",
    "Text Encoder", "Grounding", "Contrastive", "CLIP", "BLIP", "Q-Former",
    "Perceiver", "Token Compression", "LLaVA", "Instruction Tuning", "RLHF",
    "LoRA", "Evaluation", "Benchmark", "Retrieval", "OCR", "RAG", "SOTA",
    "Transformers", "Attention", "GANs", "VAEs", "Survey"
  ],
  "meta": {
    "totalPosts": 19,
    "lastUpdated": "2025-04-03T08:00:00Z",
    "version": "1.0.0",
    "author": "ThanhLamDev",
    "description": "AI Research Blog focusing on Generative AI, Flow Matching, Diffusion, and Vision-Language research"
  }
}
